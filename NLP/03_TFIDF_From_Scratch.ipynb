{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few improvisations can be done to the below code,\n",
    "1. adding extra function to split a corpus into list of documents.\n",
    "2. removing puctuations in the corpus.\n",
    "3. lowercasing the documents.\n",
    "4. .............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "corpus = [\n",
    "    'this is the first document',\n",
    "    'this document is the second document',\n",
    "    'and this is the third one',\n",
    "    'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tokenizing the given corpus\n",
    "'''\n",
    "\n",
    "def tokenize(corpus):\n",
    "    corpus_ = []\n",
    "    dic = set()\n",
    "    for sent in corpus:\n",
    "        temp = []\n",
    "        for word in sent.split(\" \"):\n",
    "            if(len(word)>1):\n",
    "                temp.append(word)\n",
    "                dic.add(word)\n",
    "        corpus_.append(temp)\n",
    "    return corpus_,sorted(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'document'], ['this', 'document', 'is', 'the', 'second', 'document'], ['and', 'this', 'is', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document']]\n",
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "corpus_,dic = tokenize(corpus)\n",
    "print(corpus_)\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating BOW for the corpus\n",
    "'''\n",
    "\n",
    "def BOW(corpus_,dic):\n",
    "    BOW = np.zeros((len(corpus_),len(dic)))\n",
    "    for i in range(len(BOW)):\n",
    "        for j in range(len(BOW[i])):\n",
    "            count=0\n",
    "            for word in corpus_[i]:\n",
    "                if word == dic[j]:\n",
    "                    count += 1\n",
    "            BOW[i][j] = count\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 0. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "BOW = BOW(corpus_,dic)\n",
    "print(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computing the Term Frequency\n",
    "'''\n",
    "\n",
    "def compute_TF(BOW,corpus_,dic):\n",
    "    TF = np.zeros((len(corpus_),len(dic)))\n",
    "    for i in range(len(BOW)):\n",
    "        for j in range(len(BOW[i])):\n",
    "            if BOW[i][j]!=0:\n",
    "                TF[i][j] = BOW[i][j]/len(corpus_[i])\n",
    "    return TF     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.2        0.2        0.2        0.         0.\n",
      "  0.2        0.         0.2       ]\n",
      " [0.         0.33333333 0.         0.16666667 0.         0.16666667\n",
      "  0.16666667 0.         0.16666667]\n",
      " [0.16666667 0.         0.         0.16666667 0.16666667 0.\n",
      "  0.16666667 0.16666667 0.16666667]\n",
      " [0.         0.2        0.2        0.2        0.         0.\n",
      "  0.2        0.         0.2       ]]\n"
     ]
    }
   ],
   "source": [
    "TF = compute_TF(BOW,corpus_,dic)\n",
    "print(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computing the inverse document frequency\n",
    "'''\n",
    "\n",
    "def compute_IDF(BOW,corpus_,dic):\n",
    "    IDF = np.zeros(len(dic))\n",
    "    for n in range(len(dic)):\n",
    "        count=0\n",
    "        for row in BOW:\n",
    "            if row[n]>0:\n",
    "                count+=1\n",
    "        IDF[n]= 1 + np.log((len(BOW)+1)/(count+1))\n",
    "    return IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "IDF = compute_IDF(BOW,corpus_,dic)\n",
    "print(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computing the TF-IDF -> TF*IDF\n",
    "'''\n",
    "\n",
    "def compute_TFIDF(TF,IDF):\n",
    "    TFIDF = np.zeros((len(corpus_),len(dic)))\n",
    "    for i in range(len(TF)):\n",
    "        for j in range(len(TF[i])):\n",
    "            TFIDF[i][j] = TF[i][j]*IDF[j]\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Before Normalization \n",
      "************************************************************\n",
      "[[0.         0.24462871 0.30216512 0.2        0.         0.\n",
      "  0.2        0.         0.2       ]\n",
      " [0.         0.40771452 0.         0.16666667 0.         0.31938179\n",
      "  0.16666667 0.         0.16666667]\n",
      " [0.31938179 0.         0.         0.16666667 0.31938179 0.\n",
      "  0.16666667 0.31938179 0.16666667]\n",
      " [0.         0.24462871 0.30216512 0.2        0.         0.\n",
      "  0.2        0.         0.2       ]]\n",
      "\n",
      " After Normalization \n",
      "************************************************************\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Before Normalization \\n\"+\"*\"*60)\n",
    "TFIDF = compute_TFIDF(TF,IDF)\n",
    "print(TFIDF)\n",
    "\n",
    "'''\n",
    "Normalizing the array\n",
    "'''\n",
    "\n",
    "print(\"\\n After Normalization \\n\"+\"*\"*60)\n",
    "TFIDF = sklearn.preprocessing.normalize(TFIDF,norm='l2')\n",
    "print(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sklearn implimentation\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "skl_TFIDF = vectorizer.transform(corpus)\n",
    "print(skl_TFIDF.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
