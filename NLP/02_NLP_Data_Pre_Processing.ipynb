{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('all')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Machine learning is a branch of artificial intelligence (AI) focused on building applications that learn from data and improve their accuracy over time without being programmed to do so. \n",
    "\n",
    "In data science, an algorithm is a sequence of statistical processing steps. In machine learning, algorithms are 'trained' to find patterns and features in massive amounts of data in order to make decisions and predictions based on new data. The better the algorithm, the more accurate the decisions and predictions will become as it processes more data.\n",
    "\n",
    "Today, examples of machine learning are all around us. Digital assistants search the web and play music in response to our voice commands. Websites recommend products and movies and songs based on what we bought, watched, or listened to before. Robots vacuum our floors while we do . . . something better with our time. Spam detectors stop unwanted emails from reaching our inboxes. Medical image analysis systems help doctors spot tumors they might have missed. And the first self-driving cars are hitting the road.\n",
    "\n",
    "We can expect more. As big data keeps getting bigger, as computing becomes more powerful and affordable, and as data scientists keep developing more capable algorithms, machine learning will drive greater and greater efficiency in our personal and work lives. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Machine learning is a branch of artificial intelligence (AI) focused on building applications that learn from data and improve their accuracy over time without being programmed to do so. \\n\\nIn data science, an algorithm is a sequence of statistical processing steps. In machine learning, algorithms are 'trained' to find patterns and features in massive amounts of data in order to make decisions and predictions based on new data. The better the algorithm, the more accurate the decisions and predictions will become as it processes more data.\\n\\nToday, examples of machine learning are all around us. Digital assistants search the web and play music in response to our voice commands. Websites recommend products and movies and songs based on what we bought, watched, or listened to before. Robots vacuum our floors while we do . . . something better with our time. Spam detectors stop unwanted emails from reaching our inboxes. Medical image analysis systems help doctors spot tumors they might have missed. And the first self-driving cars are hitting the road.\\n\\nWe can expect more. As big data keeps getting bigger, as computing becomes more powerful and affordable, and as data scientists keep developing more capable algorithms, machine learning will drive greater and greater efficiency in our personal and work lives. \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning is a branch of artificial intelligence (AI) focused on building applications that learn from data and improve their accuracy over time without being programmed to do so', ' \\n\\nIn data science, an algorithm is a sequence of statistical processing steps', \" In machine learning, algorithms are 'trained' to find patterns and features in massive amounts of data in order to make decisions and predictions based on new data\", ' The better the algorithm, the more accurate the decisions and predictions will become as it processes more data', '\\n\\nToday, examples of machine learning are all around us', ' Digital assistants search the web and play music in response to our voice commands', ' Websites recommend products and movies and songs based on what we bought, watched, or listened to before', ' Robots vacuum our floors while we do ', ' ', ' ', ' something better with our time', ' Spam detectors stop unwanted emails from reaching our inboxes', ' Medical image analysis systems help doctors spot tumors they might have missed', ' And the first self-driving cars are hitting the road', '\\n\\nWe can expect more', ' As big data keeps getting bigger, as computing becomes more powerful and affordable, and as data scientists keep developing more capable algorithms, machine learning will drive greater and greater efficiency in our personal and work lives', ' ']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sent_tokenized = sent_tokenize(doc)\n",
    "print(sent_tokenized)\n",
    "\"\"\"\n",
    "\n",
    "sentences = [sent for sent in doc.split(\".\")]\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine', 'learning', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'focused', 'on', 'building', 'applications', 'that', 'learn', 'from', 'data', 'and', 'improve', 'their', 'accuracy', 'over', 'time', 'without', 'being', 'programmed', 'to', 'do', 'so'], ['in', 'data', 'an', 'algorithm', 'is', 'a', 'sequence', 'of', 'statistical', 'processing', 'steps'], ['in', 'machine', 'algorithms', 'are', 'to', 'find', 'patterns', 'and', 'features', 'in', 'massive', 'amounts', 'of', 'data', 'in', 'order', 'to', 'make', 'decisions', 'and', 'predictions', 'based', 'on', 'new', 'data'], ['the', 'better', 'the', 'the', 'more', 'accurate', 'the', 'decisions', 'and', 'predictions', 'will', 'become', 'as', 'it', 'processes', 'more', 'data'], ['examples', 'of', 'machine', 'learning', 'are', 'all', 'around', 'us'], ['digital', 'assistants', 'search', 'the', 'web', 'and', 'play', 'music', 'in', 'response', 'to', 'our', 'voice', 'commands'], ['websites', 'recommend', 'products', 'and', 'movies', 'and', 'songs', 'based', 'on', 'what', 'we', 'or', 'listened', 'to', 'before'], ['robots', 'vacuum', 'our', 'floors', 'while', 'we', 'do'], ['something', 'better', 'with', 'our', 'time'], ['spam', 'detectors', 'stop', 'unwanted', 'emails', 'from', 'reaching', 'our', 'inboxes'], ['medical', 'image', 'analysis', 'systems', 'help', 'doctors', 'spot', 'tumors', 'they', 'might', 'have', 'missed'], ['and', 'the', 'first', 'cars', 'are', 'hitting', 'the', 'road'], ['we', 'can', 'expect', 'more'], ['as', 'big', 'data', 'keeps', 'getting', 'as', 'computing', 'becomes', 'more', 'powerful', 'and', 'and', 'as', 'data', 'scientists', 'keep', 'developing', 'more', 'capable', 'machine', 'learning', 'will', 'drive', 'greater', 'and', 'greater', 'efficiency', 'in', 'our', 'personal', 'and', 'work', 'lives']]\n",
      "\n",
      " Number of sentences - 14\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To tokenize into words\n",
    "word_tokenized = word_tokenize(doc)\n",
    "print(word_tokenized)\n",
    "\n",
    "To remove punctuations\n",
    "tokenized = RegexpTokenizer(word_tokenized)\n",
    "print(tokenized)\n",
    "\n",
    "re.sub('[^a-zA-Z]',' ',sentence)\n",
    "\"\"\"\n",
    "\n",
    "words_list = []\n",
    "for sent in sentences:\n",
    "    temp=[]\n",
    "    for word in sent.split():\n",
    "        if word.isalpha():\n",
    "            temp.append(word.lower())\n",
    "    if len(temp)!=0:\n",
    "        words_list.append(temp)\n",
    "print(words_list)\n",
    "print(\"\\n Number of sentences - \"+str(len(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine', 'learning', 'branch', 'artificial', 'intelligence', 'focused', 'building', 'applications', 'learn', 'data', 'improve', 'accuracy', 'time', 'without', 'programmed'], ['data', 'algorithm', 'sequence', 'statistical', 'processing', 'steps'], ['machine', 'algorithms', 'find', 'patterns', 'features', 'massive', 'amounts', 'data', 'order', 'make', 'decisions', 'predictions', 'based', 'new', 'data'], ['better', 'accurate', 'decisions', 'predictions', 'become', 'processes', 'data'], ['examples', 'machine', 'learning', 'around', 'us'], ['digital', 'assistants', 'search', 'web', 'play', 'music', 'response', 'voice', 'commands'], ['websites', 'recommend', 'products', 'movies', 'songs', 'based', 'listened'], ['robots', 'vacuum', 'floors'], ['something', 'better', 'time'], ['spam', 'detectors', 'stop', 'unwanted', 'emails', 'reaching', 'inboxes'], ['medical', 'image', 'analysis', 'systems', 'help', 'doctors', 'spot', 'tumors', 'might', 'missed'], ['first', 'cars', 'hitting', 'road'], ['expect'], ['big', 'data', 'keeps', 'getting', 'computing', 'becomes', 'powerful', 'data', 'scientists', 'keep', 'developing', 'capable', 'machine', 'learning', 'drive', 'greater', 'greater', 'efficiency', 'personal', 'work', 'lives']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Removing Stop Words\n",
    "\"\"\"\n",
    "words_stopword_removed=[]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for sent in words_list:\n",
    "    temp=[]\n",
    "    for word in sent:\n",
    "        if word not in stop_words:\n",
    "            temp.append(word)\n",
    "    words_stopword_removed.append(temp)\n",
    "print(words_stopword_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machin', 'learn', 'branch', 'artifici', 'intellig', 'focus', 'build', 'applic', 'learn', 'data', 'improv', 'accuraci', 'time', 'without', 'program'], ['data', 'algorithm', 'sequenc', 'statist', 'process', 'step'], ['machin', 'algorithm', 'find', 'pattern', 'featur', 'massiv', 'amount', 'data', 'order', 'make', 'decis', 'predict', 'base', 'new', 'data'], ['better', 'accur', 'decis', 'predict', 'becom', 'process', 'data'], ['exampl', 'machin', 'learn', 'around', 'us'], ['digit', 'assist', 'search', 'web', 'play', 'music', 'respons', 'voic', 'command'], ['websit', 'recommend', 'product', 'movi', 'song', 'base', 'listen'], ['robot', 'vacuum', 'floor'], ['someth', 'better', 'time'], ['spam', 'detector', 'stop', 'unwant', 'email', 'reach', 'inbox'], ['medic', 'imag', 'analysi', 'system', 'help', 'doctor', 'spot', 'tumor', 'might', 'miss'], ['first', 'car', 'hit', 'road'], ['expect'], ['big', 'data', 'keep', 'get', 'comput', 'becom', 'power', 'data', 'scientist', 'keep', 'develop', 'capabl', 'machin', 'learn', 'drive', 'greater', 'greater', 'effici', 'person', 'work', 'live']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stemming\n",
    "\"\"\"\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "words_stemed = []\n",
    "for sent in words_stopword_removed:\n",
    "    temp = []\n",
    "    for word in sent:\n",
    "        temp.append(porter.stem(word))\n",
    "    words_stemed.append(temp)\n",
    "print(words_stemed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['machine', 'learning', 'branch', 'artificial', 'intelligence', 'focused', 'building', 'application', 'learn', 'data', 'improve', 'accuracy', 'time', 'without', 'programmed'], ['data', 'algorithm', 'sequence', 'statistical', 'processing', 'step'], ['machine', 'algorithm', 'find', 'pattern', 'feature', 'massive', 'amount', 'data', 'order', 'make', 'decision', 'prediction', 'based', 'new', 'data'], ['better', 'accurate', 'decision', 'prediction', 'become', 'process', 'data'], ['example', 'machine', 'learning', 'around', 'u'], ['digital', 'assistant', 'search', 'web', 'play', 'music', 'response', 'voice', 'command'], ['website', 'recommend', 'product', 'movie', 'song', 'based', 'listened'], ['robot', 'vacuum', 'floor'], ['something', 'better', 'time'], ['spam', 'detector', 'stop', 'unwanted', 'email', 'reaching', 'inboxes'], ['medical', 'image', 'analysis', 'system', 'help', 'doctor', 'spot', 'tumor', 'might', 'missed'], ['first', 'car', 'hitting', 'road'], ['expect'], ['big', 'data', 'keep', 'getting', 'computing', 'becomes', 'powerful', 'data', 'scientist', 'keep', 'developing', 'capable', 'machine', 'learning', 'drive', 'greater', 'greater', 'efficiency', 'personal', 'work', 'life']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "lemmatization\n",
    "\"\"\"\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words_lemmatized = []\n",
    "for sent in words_stopword_removed:\n",
    "    temp = []\n",
    "    for word in sent:\n",
    "        temp.append(lemmatizer.lemmatize(word))\n",
    "    words_lemmatized.append(temp)\n",
    "print(words_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
