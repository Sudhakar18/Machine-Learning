{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0      tech  tv future in the hands of viewers with home th...\n",
       "1  business  worldcom boss  left books alone  former worldc...\n",
       "2     sport  tigers wary of farrell  gamble  leicester say ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"lsh_data.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2215</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sport</td>\n",
       "      <td>singer s film to show at festival a documentar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>509</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text\n",
       "count      2215                                               2225\n",
       "unique        5                                               2126\n",
       "top       sport  singer s film to show at festival a documentar...\n",
       "freq        509                                                  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            509\n",
       "business         508\n",
       "politics         415\n",
       "tech             399\n",
       "entertainment    384\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data has collection of news across various categories\n",
    "- Supervised learning\n",
    "- X -> text\n",
    "- Y -> category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>junk e-mails on relentless rise spam traffic i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>top stars join us tsunami tv show brad pitt  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rings of steel combat net attacks gambling is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>davies favours gloucester future wales hooker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>beijingers fume over parking fees choking traf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "2215      NaN  junk e-mails on relentless rise spam traffic i...\n",
       "2216      NaN  top stars join us tsunami tv show brad pitt  r...\n",
       "2217      NaN  rings of steel combat net attacks gambling is ...\n",
       "2218      NaN  davies favours gloucester future wales hooker ...\n",
       "2219      NaN  beijingers fume over parking fees choking traf...\n",
       "2220      NaN  cars pull down us retail figures us retail sal...\n",
       "2221      NaN  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222      NaN  rem announce new glasgow concert us band rem h...\n",
       "2223      NaN  how political squabbles snowball it s become c...\n",
       "2224      NaN  souness delight at euro progress boss graeme s..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[pd.isnull(data).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The last 10 data points are for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[pd.isnull(data).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "Number of data points2215\n",
      "   category                                               text\n",
      "0      tech  tv future in the hands of viewers with home th...\n",
      "1  business  worldcom boss  left books alone  former worldc...\n",
      "\n",
      "\n",
      "Test Data\n",
      "Number of data points10\n",
      "     category                                               text\n",
      "2215      NaN  junk e-mails on relentless rise spam traffic i...\n",
      "2216      NaN  top stars join us tsunami tv show brad pitt  r...\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data\")\n",
    "print(\"Number of data points\"+str(len(train_data)))\n",
    "print(train_data.head(2))\n",
    "print(\"\\n\")\n",
    "print(\"Test Data\")\n",
    "print(\"Number of data points\"+str(len(test_data)))\n",
    "print(test_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data['text']\n",
    "y_train = train_data['category']\n",
    "x_test = test_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,3),min_df=10,max_features=4000)\n",
    "X = vectorizer.fit(x_train)\n",
    "X = vectorizer.transform(x_train)\n",
    "test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2215, 4000)\n",
      "(10, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "hyperplanes = np.random.normal(0,1,(5,4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_combo = []\n",
    "hash_value = []\n",
    "hash_table = []\n",
    "\n",
    "def compute_dot(x,y):\n",
    "    res = []\n",
    "    for i,j in zip(x,y):\n",
    "        res.append(i*j)\n",
    "    return(sum(res))\n",
    "\n",
    "def to_hashtable(hashh,X_i):\n",
    "    if hashh not in hash_combo:\n",
    "        hash_combo.append(hashh)\n",
    "        hash_value.append([])\n",
    "    for n in range(len(hash_combo)):\n",
    "        if hash_combo[n]==hashh:\n",
    "            hash_value[n].append(X_i)\n",
    "\n",
    "def compute_len(x):\n",
    "    res=0\n",
    "    for i in x:\n",
    "        res = res + (i*i)\n",
    "    return np.sqrt(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSH(X):\n",
    "    for X_i in range(len(X.toarray())):\n",
    "        hashh=[]\n",
    "        for plane in hyperplanes:\n",
    "            if compute_dot(X[X_i].toarray()[0],plane)>=0:\n",
    "                hashh.append(1)\n",
    "            else:\n",
    "                hashh.append(-1)\n",
    "        to_hashtable(hashh,X_i)\n",
    "\n",
    "    for i,j in zip(hash_combo,hash_value):\n",
    "        temp=[]\n",
    "        temp.append(i)\n",
    "        temp.append(j)\n",
    "        hash_table.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSH(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_knn(query,k):\n",
    "    hashh=[]\n",
    "    for plane in hyperplanes:\n",
    "        if compute_dot(query,plane)>=0:\n",
    "            hashh.append(1)\n",
    "        else:\n",
    "            hashh.append(-1)\n",
    "    for i in range(len(hash_table)):\n",
    "        if hashh == hash_table[i][0]:\n",
    "            pointsInHash=hash_table[i][1]\n",
    "    dist = {}\n",
    "    for n in pointsInHash:\n",
    "        xy=compute_dot(query,X.toarray()[n])\n",
    "        x_ = compute_len(query)\n",
    "        y_ = compute_len(X.toarray()[n])\n",
    "        cos_sim = xy/(x_*y_)\n",
    "        dist[n]=cos_sim\n",
    "    dist = sorted(dist.items(), key=lambda x: x[1], reverse=True)\n",
    "    return dist[0:k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maj_vote(knn):\n",
    "    maj_vot = []\n",
    "    frequency={}\n",
    "    for i in range(len(knn)):\n",
    "        maj_vot.append(y_train[knn[i][0]])\n",
    "    for cat in maj_vot:\n",
    "        n = maj_vot.count(cat)\n",
    "        frequency[cat]=n\n",
    "    return sorted(frequency.items(), key=lambda x: x[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "classification=[]\n",
    "def predict(test):\n",
    "    for query in range(len(test.toarray())):\n",
    "        knn = compute_knn(test.toarray()[query],k)\n",
    "        majority = maj_vote(knn)\n",
    "        classification.append(majority)\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tech', 7), ('entertainment', 6), ('tech', 9), ('tech', 6), ('business', 4), ('business', 8), ('politics', 4), ('entertainment', 6), ('politics', 6), ('sport', 7)]\n"
     ]
    }
   ],
   "source": [
    "classification = predict(test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
