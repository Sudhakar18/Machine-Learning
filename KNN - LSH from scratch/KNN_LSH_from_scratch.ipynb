{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"lsh_data.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data has collection of news across various categories\n",
    "- Supervised learning\n",
    "- X -> text\n",
    "- Y -> category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[pd.isnull(data).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The last 10 data points are for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[pd.isnull(data).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Data\")\n",
    "print(\"Number of data points\"+str(len(train_data)))\n",
    "print(train_data.head(2))\n",
    "print(\"\\n\")\n",
    "print(\"Test Data\")\n",
    "print(\"Number of data points\"+str(len(test_data)))\n",
    "print(test_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data['text']\n",
    "y_train = train_data['category']\n",
    "x_test = test_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,3),min_df=10,max_features=4000)\n",
    "X = vectorizer.fit(x_train)\n",
    "X = vectorizer.transform(x_train)\n",
    "test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "hyperplanes = np.random.normal(0,1,(5,4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_combo = []\n",
    "hash_value = []\n",
    "hash_table = []\n",
    "\n",
    "def compute_dot(x,y):\n",
    "    res = []\n",
    "    for i,j in zip(x,y):\n",
    "        res.append(i*j)\n",
    "    return(sum(res))\n",
    "\n",
    "def to_hashtable(hashh,X_i):\n",
    "    if hashh not in hash_combo:\n",
    "        hash_combo.append(hashh)\n",
    "        hash_value.append([])\n",
    "    for n in range(len(hash_combo)):\n",
    "        if hash_combo[n]==hashh:\n",
    "            hash_value[n].append(X_i)\n",
    "\n",
    "def compute_len(x):\n",
    "    res=0\n",
    "    for i in x:\n",
    "        res = res + (i*i)\n",
    "    return np.sqrt(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSH(X):\n",
    "    for X_i in range(len(X.toarray())):\n",
    "        hashh=[]\n",
    "        for plane in hyperplanes:\n",
    "            if compute_dot(X[X_i].toarray()[0],plane)>=0:\n",
    "                hashh.append(1)\n",
    "            else:\n",
    "                hashh.append(-1)\n",
    "        to_hashtable(hashh,X_i)\n",
    "\n",
    "    for i,j in zip(hash_combo,hash_value):\n",
    "        temp=[]\n",
    "        temp.append(i)\n",
    "        temp.append(j)\n",
    "        hash_table.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSH(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_knn(query,k):\n",
    "    hashh=[]\n",
    "    for plane in hyperplanes:\n",
    "        if compute_dot(query,plane)>=0:\n",
    "            hashh.append(1)\n",
    "        else:\n",
    "            hashh.append(-1)\n",
    "    for i in range(len(hash_table)):\n",
    "        if hashh == hash_table[i][0]:\n",
    "            pointsInHash=hash_table[i][1]\n",
    "    dist = {}\n",
    "    for n in pointsInHash:\n",
    "        xy=compute_dot(query,X.toarray()[n])\n",
    "        x_ = compute_len(query)\n",
    "        y_ = compute_len(X.toarray()[n])\n",
    "        cos_sim = xy/(x_*y_)\n",
    "        dist[n]=cos_sim\n",
    "    dist = sorted(dist.items(), key=lambda x: x[1], reverse=True)\n",
    "    return dist[0:k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maj_vote(knn):\n",
    "    maj_vot = []\n",
    "    frequency={}\n",
    "    for i in range(len(knn)):\n",
    "        maj_vot.append(y_train[knn[i][0]])\n",
    "    for cat in maj_vot:\n",
    "        n = maj_vot.count(cat)\n",
    "        frequency[cat]=n\n",
    "    return sorted(frequency.items(), key=lambda x: x[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "classification=[]\n",
    "def predict(test):\n",
    "    for query in range(len(test.toarray())):\n",
    "        knn = compute_knn(test.toarray()[query],k)\n",
    "        majority = maj_vote(knn)\n",
    "        classification.append(majority)\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = predict(test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
